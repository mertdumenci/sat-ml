{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9519 decisions\n"
     ]
    }
   ],
   "source": [
    "# Load data.\n",
    "\n",
    "import pickle\n",
    "from satml import expression\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "DATA_FILE = 'data/sr_40.pickle'\n",
    "\n",
    "with open(DATA_FILE, 'rb') as f:\n",
    "    decisions = pickle.load(f)\n",
    "\n",
    "assert decisions is not None\n",
    "\n",
    "# Extract the maximum number of variables.\n",
    "# TODO(mert): Perhaps don't assume that the dataset is uniform in its set of free variables.\n",
    "sample_formula, _ = decisions[0]\n",
    "vocab_size = len(expression.free(sample_formula))\n",
    "\n",
    "print(\"Loaded {} decisions\".format(len(decisions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there's no meaning to variable \"names\", and LSTMs will later try to assign some meaning to them, we're going to normalize them. The first variable we see is going to be `1`, second `2`, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(decisions):\n",
    "    norm_decisions = []\n",
    "    \n",
    "    for formula, (var, assignment) in decisions:\n",
    "        var_map = {}\n",
    "        formula = expression.rename(formula, var_map=var_map)\n",
    "        \n",
    "        norm_decisions.append((formula, (var_map[var], assignment)))\n",
    "        \n",
    "    return norm_decisions\n",
    "        \n",
    "decisions = normalize_dataset(decisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the normalized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 = False in formula: ((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((-1 ∨ (-2 ∨ (-3 ∨ (-4 ∨ (5 ∨ 6))))) ∧ (-7 ∨ (-8 ∨ (-9 ∨ (10 ∨ (-11 ∨ -12)))))) ∧ (-13 ∨ (-14 ∨ (-15 ∨ (6 ∨ (16 ∨ 3)))))) ∧ (1 ∨ (17 ∨ (18 ∨ 19)))) ∧ (-4 ∨ (-20 ∨ (-5 ∨ (21 ∨ (13 ∨ (-1 ∨ (-11 ∨ (-15 ∨ (-9 ∨ -22)))))))))) ∧ (-13 ∨ (-23 ∨ -24))) ∧ (-25 ∨ (17 ∨ (10 ∨ (-3 ∨ (-26 ∨ (-27 ∨ (28 ∨ -29)))))))) ∧ (-30 ∨ 9)) ∧ (31 ∨ (16 ∨ 11))) ∧ (32 ∨ (29 ∨ 18))) ∧ (33 ∨ (34 ∨ (-35 ∨ 3)))) ∧ (-19 ∨ 26)) ∧ (-17 ∨ (-36 ∨ (11 ∨ 35)))) ∧ (-3 ∨ (-32 ∨ (-37 ∨ 20)))) ∧ (-10 ∨ (-38 ∨ (32 ∨ (-26 ∨ -7))))) ∧ (-37 ∨ (2 ∨ (-23 ∨ 18)))) ∧ (-3 ∨ (-35 ∨ 17))) ∧ (-16 ∨ (9 ∨ (-12 ∨ 19)))) ∧ (-32 ∨ (-38 ∨ -35))) ∧ (-15 ∨ (19 ∨ (14 ∨ -27)))) ∧ (12 ∨ (29 ∨ (-34 ∨ (6 ∨ (17 ∨ (-36 ∨ -39))))))) ∧ (-30 ∨ (26 ∨ 25))) ∧ (21 ∨ (20 ∨ -2))) ∧ (1 ∨ (25 ∨ -4))) ∧ (19 ∨ (3 ∨ -40))) ∧ (-4 ∨ (18 ∨ (19 ∨ (15 ∨ (-25 ∨ (-12 ∨ (17 ∨ (-8 ∨ -28))))))))) ∧ (20 ∨ (-37 ∨ 19))) ∧ (33 ∨ (-36 ∨ (-6 ∨ (11 ∨ (-37 ∨ (40 ∨ 5))))))) ∧ (20 ∨ (-35 ∨ -15))) ∧ (-24 ∨ (31 ∨ (32 ∨ (19 ∨ 23))))) ∧ (-32 ∨ (-17 ∨ (-23 ∨ -37)))) ∧ (31 ∨ (7 ∨ (-36 ∨ (19 ∨ (-20 ∨ (-30 ∨ (-9 ∨ (1 ∨ (-27 ∨ (5 ∨ -38))))))))))) ∧ (13 ∨ (27 ∨ 36))) ∧ (7 ∨ (19 ∨ (-24 ∨ (-15 ∨ -16))))) ∧ (-11 ∨ (-5 ∨ (-25 ∨ (28 ∨ -17))))) ∧ (18 ∨ (-32 ∨ (-11 ∨ (-31 ∨ (37 ∨ -6)))))) ∧ (32 ∨ (4 ∨ (-19 ∨ (-20 ∨ (-10 ∨ 27)))))) ∧ (-9 ∨ (-33 ∨ 15))) ∧ (-35 ∨ (38 ∨ (25 ∨ 7)))) ∧ (-19 ∨ -26)) ∧ (27 ∨ (13 ∨ -34))) ∧ (-13 ∨ (37 ∨ (21 ∨ -20)))) ∧ (-35 ∨ (-4 ∨ 21))) ∧ (19 ∨ (18 ∨ 3))) ∧ (-20 ∨ (37 ∨ -8))) ∧ (29 ∨ (-18 ∨ (-28 ∨ 27)))) ∧ (-17 ∨ (-9 ∨ -35))) ∧ (31 ∨ -9)) ∧ (37 ∨ (4 ∨ (-11 ∨ (-18 ∨ (-15 ∨ 17)))))) ∧ (-10 ∨ (32 ∨ (23 ∨ (-12 ∨ -31))))) ∧ (13 ∨ (30 ∨ -23))) ∧ (-31 ∨ (-28 ∨ (15 ∨ (39 ∨ (-12 ∨ 13)))))) ∧ (-1 ∨ (38 ∨ -27))) ∧ (-34 ∨ (-4 ∨ (-39 ∨ 1)))) ∧ (26 ∨ (-2 ∨ -29))) ∧ (37 ∨ 24)) ∧ (-15 ∨ 27)) ∧ (-25 ∨ (-36 ∨ (-38 ∨ (-29 ∨ 34))))) ∧ (-4 ∨ (-24 ∨ (-38 ∨ -2)))) ∧ (31 ∨ (-19 ∨ 26))) ∧ (-35 ∨ (-25 ∨ 24))) ∧ (-40 ∨ (-11 ∨ 39))) ∧ (11 ∨ (33 ∨ 18))) ∧ (-31 ∨ (-16 ∨ (-13 ∨ (34 ∨ (1 ∨ 7)))))) ∧ (1 ∨ (-11 ∨ (22 ∨ -7)))) ∧ (1 ∨ (-14 ∨ (24 ∨ (-28 ∨ (25 ∨ (2 ∨ (40 ∨ (-31 ∨ -21))))))))) ∧ (-24 ∨ (-8 ∨ 37))) ∧ (-21 ∨ (-16 ∨ -14))) ∧ (-13 ∨ (-9 ∨ (-33 ∨ (3 ∨ 31))))) ∧ (-24 ∨ (2 ∨ (21 ∨ (-25 ∨ (-16 ∨ -1)))))) ∧ (24 ∨ (-13 ∨ 5))) ∧ (13 ∨ (38 ∨ (14 ∨ 25)))) ∧ (5 ∨ (-19 ∨ (-25 ∨ -1)))) ∧ (-30 ∨ (22 ∨ 37))) ∧ (-17 ∨ 14)) ∧ (26 ∨ (29 ∨ -40))) ∧ (11 ∨ (-12 ∨ (-14 ∨ -28)))) ∧ (-29 ∨ 38)) ∧ (-2 ∨ (35 ∨ (27 ∨ (-40 ∨ (-33 ∨ -16)))))) ∧ (7 ∨ (31 ∨ -9))) ∧ (-26 ∨ (4 ∨ 13))) ∧ (-2 ∨ (-40 ∨ (-23 ∨ -4)))) ∧ (1 ∨ (-38 ∨ (16 ∨ (25 ∨ (28 ∨ 22)))))) ∧ (-35 ∨ -10)) ∧ (-35 ∨ (-22 ∨ 6))) ∧ (32 ∨ (21 ∨ (26 ∨ 6)))) ∧ (-20 ∨ (29 ∨ (-23 ∨ (-34 ∨ -13))))) ∧ (-1 ∨ -20)) ∧ (16 ∨ (-14 ∨ -39))) ∧ (14 ∨ (-17 ∨ (35 ∨ 25)))) ∧ (-39 ∨ (6 ∨ -22))) ∧ (-17 ∨ (29 ∨ (-7 ∨ 26)))) ∧ (-32 ∨ (15 ∨ (-19 ∨ -28)))) ∧ (-17 ∨ (-4 ∨ (33 ∨ (-36 ∨ (14 ∨ (-23 ∨ (-34 ∨ (25 ∨ (-13 ∨ (-29 ∨ -18))))))))))) ∧ (17 ∨ (-33 ∨ 10))) ∧ (-23 ∨ (-37 ∨ (-26 ∨ (16 ∨ -9))))) ∧ (7 ∨ (2 ∨ (-26 ∨ -36)))) ∧ (3 ∨ (28 ∨ (-6 ∨ (32 ∨ (-14 ∨ (-7 ∨ 34))))))) ∧ (-17 ∨ (36 ∨ -4))) ∧ (-12 ∨ (-31 ∨ (-26 ∨ (27 ∨ 23))))) ∧ (-17 ∨ (19 ∨ (26 ∨ (-21 ∨ (-25 ∨ (-8 ∨ (13 ∨ (9 ∨ -20))))))))) ∧ (5 ∨ (-32 ∨ (-27 ∨ 3)))) ∧ (-17 ∨ (13 ∨ -32))) ∧ (-20 ∨ (11 ∨ 31))) ∧ (33 ∨ (39 ∨ -20))) ∧ (-18 ∨ -37)) ∧ (22 ∨ (1 ∨ (11 ∨ (-10 ∨ (-13 ∨ -17)))))) ∧ (35 ∨ (13 ∨ (21 ∨ -25)))) ∧ (-5 ∨ (31 ∨ -10))) ∧ (-22 ∨ (-32 ∨ 9))) ∧ (19 ∨ (8 ∨ 2))) ∧ (25 ∨ (24 ∨ (19 ∨ (9 ∨ 11))))) ∧ (38 ∨ (-20 ∨ (-1 ∨ -32)))) ∧ (17 ∨ (19 ∨ 35))) ∧ (40 ∨ (7 ∨ (5 ∨ 18)))) ∧ (-22 ∨ (-37 ∨ (-9 ∨ (-8 ∨ (-33 ∨ (-12 ∨ -13))))))) ∧ (14 ∨ (-40 ∨ (7 ∨ (-29 ∨ (20 ∨ 27)))))) ∧ (34 ∨ (-6 ∨ (-18 ∨ -24)))) ∧ (-7 ∨ 20)) ∧ (-38 ∨ 14)) ∧ (-16 ∨ (25 ∨ (9 ∨ (-21 ∨ (-22 ∨ -26)))))) ∧ (40 ∨ (32 ∨ (25 ∨ (-19 ∨ (-20 ∨ (4 ∨ (30 ∨ 8)))))))) ∧ (-31 ∨ -34)) ∧ (-32 ∨ (-14 ∨ (19 ∨ -31)))) ∧ (38 ∨ (-26 ∨ (-27 ∨ (33 ∨ (-11 ∨ (-15 ∨ 17))))))) ∧ (-14 ∨ (31 ∨ 19))) ∧ (2 ∨ (-31 ∨ 8))) ∧ (38 ∨ -20)) ∧ (-22 ∨ (-35 ∨ (-26 ∨ 17)))) ∧ (20 ∨ (-2 ∨ (33 ∨ (-40 ∨ -6))))) ∧ (-25 ∨ (-32 ∨ (-38 ∨ 35)))) ∧ (-18 ∨ (-33 ∨ (-37 ∨ (-21 ∨ (19 ∨ 4)))))) ∧ (7 ∨ (-11 ∨ 3))) ∧ (-9 ∨ (-27 ∨ -23))) ∧ (-11 ∨ (-4 ∨ -39))) ∧ (24 ∨ (16 ∨ (-15 ∨ (-29 ∨ -17))))) ∧ (-33 ∨ (-9 ∨ (24 ∨ 8)))) ∧ (20 ∨ (-34 ∨ -33))) ∧ (40 ∨ (31 ∨ (-19 ∨ (-4 ∨ -16))))) ∧ (-39 ∨ (40 ∨ (34 ∨ 35)))) ∧ (-5 ∨ 9)) ∧ (9 ∨ (37 ∨ (-39 ∨ (-33 ∨ (-19 ∨ (22 ∨ (30 ∨ (3 ∨ 31))))))))) ∧ (30 ∨ -9)) ∧ (-21 ∨ (-24 ∨ -38))) ∧ (-2 ∨ (38 ∨ -28))) ∧ (-15 ∨ (-3 ∨ (18 ∨ -28)))) ∧ (-4 ∨ (23 ∨ 39))) ∧ (-28 ∨ (13 ∨ (-31 ∨ (-25 ∨ (-24 ∨ (20 ∨ -5))))))) ∧ (-7 ∨ (2 ∨ 36))) ∧ (39 ∨ (-27 ∨ -17))) ∧ (22 ∨ (-16 ∨ (19 ∨ 28)))) ∧ (39 ∨ (22 ∨ (12 ∨ (23 ∨ (29 ∨ (11 ∨ (6 ∨ -38)))))))) ∧ (-11 ∨ -10)) ∧ (-40 ∨ (-30 ∨ (27 ∨ 5)))) ∧ (8 ∨ (36 ∨ -9))) ∧ (32 ∨ (15 ∨ (-16 ∨ -31)))) ∧ (6 ∨ (14 ∨ (33 ∨ (-16 ∨ (19 ∨ -29)))))) ∧ (-2 ∨ (19 ∨ (39 ∨ -33)))) ∧ (-32 ∨ -25)) ∧ (-8 ∨ (16 ∨ -33))) ∧ (40 ∨ (-18 ∨ (7 ∨ 14)))) ∧ (26 ∨ (-22 ∨ -9))) ∧ (27 ∨ (-29 ∨ (3 ∨ (15 ∨ -34))))) ∧ (-27 ∨ 3)) ∧ (40 ∨ (-28 ∨ (-14 ∨ (11 ∨ (33 ∨ (-19 ∨ (20 ∨ 38)))))))) ∧ (27 ∨ (31 ∨ (-16 ∨ 21)))) ∧ (-13 ∨ (-11 ∨ (4 ∨ 12)))) ∧ (39 ∨ (40 ∨ 35))) ∧ (7 ∨ (37 ∨ (6 ∨ (23 ∨ (-33 ∨ -12)))))) ∧ (15 ∨ (30 ∨ (-34 ∨ (-17 ∨ (35 ∨ 6)))))) ∧ (-8 ∨ (20 ∨ (10 ∨ (-38 ∨ 3))))) ∧ (-10 ∨ (35 ∨ (-29 ∨ (-38 ∨ (-31 ∨ (-6 ∨ (3 ∨ -34)))))))) ∧ (29 ∨ (36 ∨ (9 ∨ 26)))) ∧ (28 ∨ -32)) ∧ (-28 ∨ (8 ∨ 19))) ∧ (-16 ∨ 12)) ∧ (33 ∨ (37 ∨ (28 ∨ (32 ∨ 15))))) ∧ (-10 ∨ (-1 ∨ (36 ∨ (26 ∨ (-28 ∨ -37)))))) ∧ (2 ∨ (35 ∨ 27))) ∧ (39 ∨ (34 ∨ (9 ∨ (11 ∨ (31 ∨ (40 ∨ (15 ∨ (-13 ∨ 5))))))))) ∧ (-21 ∨ (-1 ∨ (10 ∨ (34 ∨ (22 ∨ (11 ∨ 7))))))) ∧ (-27 ∨ (-11 ∨ 30)))\n",
      "3 = False in formula: (((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((-1 ∨ -2) ∧ (-3 ∨ (4 ∨ -5))) ∧ (-6 ∨ (-7 ∨ (8 ∨ (-9 ∨ 10))))) ∧ (11 ∨ (-12 ∨ (13 ∨ (14 ∨ -2))))) ∧ (15 ∨ -16)) ∧ (17 ∨ (18 ∨ (19 ∨ -20)))) ∧ (21 ∨ (19 ∨ -5))) ∧ (16 ∨ (-22 ∨ (13 ∨ (-7 ∨ 9))))) ∧ (-20 ∨ (17 ∨ 21))) ∧ (23 ∨ (10 ∨ 24))) ∧ (-17 ∨ (-18 ∨ (-12 ∨ -24)))) ∧ (17 ∨ (-15 ∨ (3 ∨ (-11 ∨ (-7 ∨ (-9 ∨ (-8 ∨ -25)))))))) ∧ (-26 ∨ (-3 ∨ (20 ∨ -15)))) ∧ (1 ∨ (24 ∨ 27))) ∧ (-28 ∨ (26 ∨ (25 ∨ (22 ∨ 14))))) ∧ (29 ∨ (26 ∨ -12))) ∧ (-22 ∨ (3 ∨ (-20 ∨ (26 ∨ (-8 ∨ 13)))))) ∧ (16 ∨ (-11 ∨ (21 ∨ 17)))) ∧ (10 ∨ (-8 ∨ 3))) ∧ (-13 ∨ (-3 ∨ (25 ∨ 22)))) ∧ (-1 ∨ (24 ∨ -17))) ∧ (-30 ∨ (20 ∨ 4))) ∧ (30 ∨ (-1 ∨ -4))) ∧ (-21 ∨ (-18 ∨ 6))) ∧ (16 ∨ (-31 ∨ (-32 ∨ (33 ∨ -1))))) ∧ (1 ∨ (-25 ∨ (-8 ∨ (-15 ∨ 6))))) ∧ (15 ∨ 5)) ∧ (-16 ∨ (14 ∨ (30 ∨ (-28 ∨ 18))))) ∧ (21 ∨ (-8 ∨ (34 ∨ -17)))) ∧ (35 ∨ (27 ∨ (16 ∨ (34 ∨ -15))))) ∧ (21 ∨ (10 ∨ 1))) ∧ (30 ∨ (-33 ∨ (1 ∨ (36 ∨ (31 ∨ -34)))))) ∧ (-10 ∨ (34 ∨ (-36 ∨ -14)))) ∧ (6 ∨ (-2 ∨ -23))) ∧ (-22 ∨ 3)) ∧ (25 ∨ (5 ∨ (27 ∨ (-19 ∨ -22))))) ∧ (10 ∨ (-34 ∨ (35 ∨ 22)))) ∧ (-9 ∨ (-18 ∨ (-36 ∨ -30)))) ∧ (22 ∨ (-17 ∨ (4 ∨ 6)))) ∧ (-17 ∨ (12 ∨ (29 ∨ -19)))) ∧ (12 ∨ (9 ∨ (2 ∨ (-6 ∨ 36))))) ∧ (-3 ∨ (33 ∨ (-27 ∨ (11 ∨ -32))))) ∧ (-26 ∨ (-25 ∨ (-37 ∨ (-31 ∨ 38))))) ∧ (39 ∨ (16 ∨ (-1 ∨ (-13 ∨ 18))))) ∧ (18 ∨ (11 ∨ 36))) ∧ (-18 ∨ (-40 ∨ -2))) ∧ (-14 ∨ 13)) ∧ (5 ∨ (-10 ∨ 23))) ∧ (32 ∨ -28)) ∧ (-36 ∨ (6 ∨ (-40 ∨ (-9 ∨ -22))))) ∧ (-20 ∨ (-31 ∨ (-6 ∨ -34)))) ∧ (22 ∨ (-10 ∨ (-9 ∨ (14 ∨ (16 ∨ (-8 ∨ (-1 ∨ (-35 ∨ (-19 ∨ 25)))))))))) ∧ (18 ∨ (36 ∨ (16 ∨ 8)))) ∧ (-24 ∨ (-35 ∨ (-30 ∨ -5)))) ∧ (23 ∨ (-13 ∨ -39))) ∧ (-19 ∨ (6 ∨ (-35 ∨ -13)))) ∧ (7 ∨ (6 ∨ 21))) ∧ (32 ∨ (38 ∨ (14 ∨ -21)))) ∧ (9 ∨ (-4 ∨ (-2 ∨ (-8 ∨ (34 ∨ 24)))))) ∧ (-12 ∨ (20 ∨ 36))) ∧ (-30 ∨ (27 ∨ (-33 ∨ (-26 ∨ (-17 ∨ (14 ∨ 8))))))) ∧ (-10 ∨ (-30 ∨ (-8 ∨ (28 ∨ 38))))) ∧ (19 ∨ (14 ∨ (-25 ∨ -16)))) ∧ (29 ∨ (-12 ∨ (1 ∨ (-8 ∨ -22))))) ∧ (35 ∨ (36 ∨ 8))) ∧ (34 ∨ (-30 ∨ (3 ∨ (-10 ∨ -36))))) ∧ (39 ∨ -33)) ∧ (12 ∨ (31 ∨ 14))) ∧ (14 ∨ (24 ∨ -32))) ∧ (-12 ∨ (22 ∨ -16))) ∧ (40 ∨ (-10 ∨ (31 ∨ (-2 ∨ (13 ∨ 6)))))) ∧ (-7 ∨ (24 ∨ (32 ∨ -2)))) ∧ (-16 ∨ -12)) ∧ (19 ∨ (33 ∨ (23 ∨ -12)))) ∧ (-33 ∨ (-19 ∨ (-18 ∨ (30 ∨ 7))))) ∧ (1 ∨ (20 ∨ (-7 ∨ (-17 ∨ -12))))) ∧ (2 ∨ (39 ∨ (19 ∨ (16 ∨ (-7 ∨ 8)))))) ∧ (-14 ∨ (34 ∨ -35))) ∧ (40 ∨ (-10 ∨ (15 ∨ (-31 ∨ (-32 ∨ (27 ∨ -39))))))) ∧ (13 ∨ (9 ∨ (-1 ∨ (-24 ∨ (-20 ∨ 19)))))) ∧ (40 ∨ (16 ∨ 10))) ∧ (-2 ∨ (17 ∨ (-32 ∨ -23)))) ∧ (19 ∨ (6 ∨ 25))) ∧ (28 ∨ (-31 ∨ (38 ∨ (-14 ∨ (3 ∨ (35 ∨ 8))))))) ∧ (23 ∨ (13 ∨ (25 ∨ (-31 ∨ (-9 ∨ (36 ∨ (-19 ∨ -34)))))))) ∧ (17 ∨ (-15 ∨ -16))) ∧ (10 ∨ (31 ∨ (23 ∨ (-33 ∨ (36 ∨ (37 ∨ 17))))))) ∧ (5 ∨ (7 ∨ (-20 ∨ (14 ∨ -17))))) ∧ (2 ∨ (-11 ∨ (-19 ∨ (-8 ∨ (36 ∨ 26)))))) ∧ (-4 ∨ (30 ∨ (16 ∨ -14)))) ∧ (-2 ∨ 32)) ∧ (17 ∨ (27 ∨ -23))) ∧ (-14 ∨ (-5 ∨ 4))) ∧ (13 ∨ -2)) ∧ (30 ∨ (3 ∨ 8))) ∧ (24 ∨ (38 ∨ (22 ∨ (10 ∨ (-1 ∨ (23 ∨ (33 ∨ (-27 ∨ (-17 ∨ (39 ∨ (-18 ∨ (32 ∨ -12))))))))))))) ∧ (11 ∨ (-17 ∨ 34))) ∧ (4 ∨ (38 ∨ -3))) ∧ (25 ∨ (-33 ∨ -12))) ∧ (34 ∨ -10)) ∧ (36 ∨ (-5 ∨ (14 ∨ (-24 ∨ -38))))) ∧ (-35 ∨ -34)) ∧ (7 ∨ (32 ∨ (-23 ∨ -17)))) ∧ (21 ∨ -30)) ∧ (-36 ∨ (-13 ∨ (-18 ∨ (14 ∨ (-7 ∨ (24 ∨ (27 ∨ (5 ∨ (-6 ∨ -37)))))))))) ∧ (-14 ∨ -4)) ∧ (5 ∨ (-1 ∨ 31))) ∧ (35 ∨ (-6 ∨ (-32 ∨ (13 ∨ (10 ∨ 27)))))) ∧ (-16 ∨ (7 ∨ 13))) ∧ (-8 ∨ (-37 ∨ 5))) ∧ (-16 ∨ (-38 ∨ (-22 ∨ (35 ∨ 2))))) ∧ (-26 ∨ (39 ∨ (18 ∨ 21)))) ∧ (36 ∨ -6)) ∧ (15 ∨ (-28 ∨ 10))) ∧ (-38 ∨ (-6 ∨ -7))) ∧ (6 ∨ (-23 ∨ -24))) ∧ (22 ∨ (-6 ∨ 11))) ∧ (-6 ∨ (32 ∨ (-5 ∨ (36 ∨ (-29 ∨ (2 ∨ -28))))))) ∧ (-36 ∨ (23 ∨ 9))) ∧ (-8 ∨ (34 ∨ 32))) ∧ (-15 ∨ (-20 ∨ (33 ∨ -32)))) ∧ (-34 ∨ (4 ∨ (-15 ∨ (-35 ∨ (10 ∨ (11 ∨ (-33 ∨ (31 ∨ (6 ∨ (17 ∨ (3 ∨ (-29 ∨ (-13 ∨ -37)))))))))))))) ∧ (-31 ∨ 10)) ∧ (37 ∨ (-7 ∨ 40))) ∧ (-37 ∨ (21 ∨ -20))) ∧ (40 ∨ (13 ∨ (-1 ∨ 2)))) ∧ (-36 ∨ (1 ∨ 31))) ∧ (-10 ∨ (-26 ∨ (-40 ∨ 8)))) ∧ (-8 ∨ (-31 ∨ (11 ∨ (2 ∨ (37 ∨ -25)))))) ∧ (-9 ∨ (40 ∨ 39))) ∧ (30 ∨ 37)) ∧ (22 ∨ (-36 ∨ (-37 ∨ (-1 ∨ 29))))) ∧ (15 ∨ (7 ∨ (37 ∨ 32)))) ∧ (23 ∨ 9)) ∧ (-19 ∨ (33 ∨ -12))) ∧ (15 ∨ (-11 ∨ (-37 ∨ (-18 ∨ (33 ∨ -12)))))) ∧ (-1 ∨ (-31 ∨ (14 ∨ -19)))) ∧ (22 ∨ (-33 ∨ 24))) ∧ (14 ∨ (-38 ∨ (-22 ∨ (39 ∨ (21 ∨ (-33 ∨ (1 ∨ (25 ∨ 32))))))))) ∧ (35 ∨ (-38 ∨ 9))) ∧ (37 ∨ (24 ∨ -11))) ∧ (3 ∨ (-32 ∨ (-12 ∨ -35)))) ∧ (-27 ∨ (-5 ∨ (-24 ∨ -39)))) ∧ (13 ∨ (-5 ∨ (24 ∨ (3 ∨ -29))))) ∧ (-40 ∨ (-10 ∨ (11 ∨ (5 ∨ (31 ∨ -24)))))) ∧ (-15 ∨ (31 ∨ -33))) ∧ (5 ∨ (-28 ∨ -15))) ∧ (11 ∨ (-35 ∨ 40))) ∧ (12 ∨ (37 ∨ 27))) ∧ (-12 ∨ (-13 ∨ (17 ∨ (-16 ∨ -8))))) ∧ (33 ∨ (15 ∨ (-19 ∨ (18 ∨ 11))))) ∧ (-1 ∨ (29 ∨ (15 ∨ 37)))) ∧ (-10 ∨ (-22 ∨ (-40 ∨ -29)))) ∧ (-23 ∨ (-27 ∨ 36))) ∧ (-39 ∨ (-33 ∨ 22))) ∧ (-27 ∨ (14 ∨ (20 ∨ -2)))) ∧ (-10 ∨ (40 ∨ -25))) ∧ (7 ∨ (12 ∨ (22 ∨ (-34 ∨ (9 ∨ 24)))))) ∧ (18 ∨ (-14 ∨ (38 ∨ -22)))) ∧ (6 ∨ 1)) ∧ (18 ∨ (27 ∨ (-29 ∨ (-14 ∨ (-35 ∨ -1)))))) ∧ (-6 ∨ (1 ∨ (-37 ∨ (-19 ∨ (28 ∨ (29 ∨ 7))))))) ∧ (35 ∨ (13 ∨ -27))) ∧ (25 ∨ (-5 ∨ -9))) ∧ (-23 ∨ (31 ∨ (3 ∨ 36)))) ∧ (32 ∨ (40 ∨ (-24 ∨ 36)))) ∧ (6 ∨ (-19 ∨ (38 ∨ (37 ∨ 5))))) ∧ (-22 ∨ -26)) ∧ (-6 ∨ (26 ∨ 14))) ∧ (29 ∨ (26 ∨ (-24 ∨ 17)))) ∧ (2 ∨ (33 ∨ (31 ∨ -30)))) ∧ (4 ∨ (-34 ∨ (-7 ∨ (-25 ∨ (36 ∨ (-29 ∨ (27 ∨ (37 ∨ (-18 ∨ (28 ∨ (-6 ∨ (-35 ∨ (-33 ∨ (-38 ∨ (-2 ∨ (12 ∨ (20 ∨ 26)))))))))))))))))) ∧ (3 ∨ (-18 ∨ (6 ∨ (-32 ∨ (-38 ∨ (36 ∨ -33))))))) ∧ (14 ∨ (-13 ∨ (-5 ∨ -38)))) ∧ (-29 ∨ (-10 ∨ -6))) ∧ (40 ∨ (-23 ∨ (8 ∨ 25)))) ∧ (13 ∨ (-27 ∨ -32))) ∧ (38 ∨ (32 ∨ (-1 ∨ (26 ∨ (-8 ∨ -23)))))) ∧ (2 ∨ 24)) ∧ (-5 ∨ (-40 ∨ (-17 ∨ -15)))) ∧ (-39 ∨ (10 ∨ 20))) ∧ (10 ∨ -40)) ∧ (-20 ∨ (-5 ∨ (11 ∨ (-4 ∨ 16))))) ∧ (5 ∨ (-26 ∨ -21))) ∧ (2 ∨ (-16 ∨ 27))) ∧ (1 ∨ (-35 ∨ (9 ∨ (38 ∨ (16 ∨ -11)))))) ∧ (-22 ∨ (30 ∨ (-18 ∨ -28)))) ∧ (17 ∨ (-35 ∨ (2 ∨ -21)))) ∧ (-20 ∨ 39)) ∧ (24 ∨ (-39 ∨ (-40 ∨ (-7 ∨ (-3 ∨ -11)))))) ∧ (15 ∨ (7 ∨ 22))) ∧ (16 ∨ (5 ∨ (28 ∨ (-15 ∨ (3 ∨ -6)))))) ∧ (-24 ∨ (36 ∨ (-30 ∨ (-40 ∨ 13))))) ∧ (-20 ∨ (-13 ∨ 38))) ∧ (22 ∨ (-38 ∨ (-15 ∨ (32 ∨ -4))))) ∧ (-17 ∨ (10 ∨ (-9 ∨ -29)))) ∧ (25 ∨ (36 ∨ (-19 ∨ (-35 ∨ 5))))) ∧ (12 ∨ (-26 ∨ (-21 ∨ (-3 ∨ (-28 ∨ (14 ∨ (-16 ∨ (-40 ∨ (-31 ∨ (20 ∨ -5))))))))))) ∧ (-19 ∨ (26 ∨ -33))) ∧ (-9 ∨ (10 ∨ (-6 ∨ 11)))) ∧ (-27 ∨ (-23 ∨ (-32 ∨ -16)))) ∧ (13 ∨ (-23 ∨ (1 ∨ (-5 ∨ (34 ∨ (-11 ∨ 26))))))) ∧ (4 ∨ (13 ∨ -12))) ∧ (10 ∨ (14 ∨ (-6 ∨ (34 ∨ (-4 ∨ 21)))))) ∧ (-38 ∨ (27 ∨ (-31 ∨ 20)))) ∧ (-14 ∨ (-6 ∨ -31))) ∧ (2 ∨ (-11 ∨ (-21 ∨ 25)))) ∧ (-8 ∨ -33)) ∧ (-37 ∨ (13 ∨ (12 ∨ 5)))) ∧ (30 ∨ (-28 ∨ 10))) ∧ (-35 ∨ (-9 ∨ (-17 ∨ (-12 ∨ (-8 ∨ (31 ∨ 19))))))) ∧ (-11 ∨ (8 ∨ (30 ∨ 38)))) ∧ (-35 ∨ (-38 ∨ -36))) ∧ (-7 ∨ 6)) ∧ (1 ∨ (25 ∨ -2))) ∧ (-18 ∨ (17 ∨ (14 ∨ (-2 ∨ (35 ∨ (1 ∨ (26 ∨ (-24 ∨ -29))))))))) ∧ (22 ∨ (25 ∨ (10 ∨ (-32 ∨ (14 ∨ (-13 ∨ -28))))))) ∧ (23 ∨ (-28 ∨ (-22 ∨ (-29 ∨ 4))))) ∧ (-29 ∨ (4 ∨ -35))) ∧ (-29 ∨ (-18 ∨ 13))) ∧ (15 ∨ (-38 ∨ 16))) ∧ (18 ∨ (-9 ∨ (20 ∨ (19 ∨ (36 ∨ (-3 ∨ (21 ∨ 25)))))))) ∧ (20 ∨ (32 ∨ -8))) ∧ (-19 ∨ (-25 ∨ (-12 ∨ 5)))) ∧ (8 ∨ (26 ∨ (27 ∨ (4 ∨ -34))))) ∧ (18 ∨ (-27 ∨ (-35 ∨ -9)))) ∧ (14 ∨ (3 ∨ -15))) ∧ (18 ∨ 6)) ∧ (9 ∨ (29 ∨ -31))) ∧ (12 ∨ (5 ∨ -28))) ∧ (-12 ∨ (-22 ∨ (38 ∨ (-6 ∨ 20))))) ∧ (-29 ∨ (-39 ∨ 32))) ∧ (-15 ∨ 12)) ∧ (-19 ∨ (39 ∨ (-17 ∨ (-15 ∨ 26))))) ∧ (33 ∨ (-4 ∨ (27 ∨ (12 ∨ (29 ∨ -14)))))) ∧ (15 ∨ (18 ∨ (-9 ∨ -22)))) ∧ (2 ∨ (40 ∨ -1))) ∧ (-22 ∨ (20 ∨ 23))) ∧ (22 ∨ (8 ∨ (23 ∨ 6)))) ∧ (17 ∨ (-4 ∨ (3 ∨ 15)))) ∧ (-12 ∨ (26 ∨ -25))) ∧ (-26 ∨ (-36 ∨ 27))) ∧ (-12 ∨ (19 ∨ (-2 ∨ (-39 ∨ (15 ∨ (-16 ∨ 32))))))) ∧ (-13 ∨ -18)) ∧ (-25 ∨ (11 ∨ 36))) ∧ (-34 ∨ (-1 ∨ (-39 ∨ 7)))) ∧ (-30 ∨ (37 ∨ (26 ∨ -40)))) ∧ (27 ∨ (18 ∨ (39 ∨ (1 ∨ -13))))) ∧ (22 ∨ (-2 ∨ (-17 ∨ (19 ∨ 14))))) ∧ (-24 ∨ (13 ∨ (8 ∨ (3 ∨ (-16 ∨ -28)))))) ∧ (4 ∨ (23 ∨ -36))) ∧ (-11 ∨ (38 ∨ (-34 ∨ (-28 ∨ (-3 ∨ (32 ∨ (29 ∨ 25)))))))) ∧ (-22 ∨ (39 ∨ (19 ∨ (12 ∨ -9))))) ∧ (18 ∨ (36 ∨ (14 ∨ 17)))) ∧ (13 ∨ (8 ∨ -11))) ∧ (-16 ∨ (-22 ∨ (-18 ∨ (33 ∨ (17 ∨ -15)))))) ∧ (23 ∨ (-11 ∨ (12 ∨ 1)))) ∧ (-1 ∨ (-33 ∨ -17))) ∧ (-38 ∨ (27 ∨ (20 ∨ (-34 ∨ -22))))) ∧ (-17 ∨ (-35 ∨ -13))) ∧ (-1 ∨ (17 ∨ 34))) ∧ (-21 ∨ (-36 ∨ (-8 ∨ (28 ∨ (-23 ∨ (32 ∨ (34 ∨ (12 ∨ (10 ∨ (35 ∨ (-25 ∨ (-19 ∨ (18 ∨ (1 ∨ 7))))))))))))))) ∧ (-10 ∨ (29 ∨ (27 ∨ 8)))) ∧ (-11 ∨ 13)) ∧ (10 ∨ (-3 ∨ (-7 ∨ 31)))) ∧ (-25 ∨ (-14 ∨ -20))) ∧ (2 ∨ (-31 ∨ (40 ∨ (36 ∨ 16))))) ∧ (28 ∨ (25 ∨ 10))) ∧ (7 ∨ -22)) ∧ (2 ∨ (-31 ∨ 40))) ∧ (-28 ∨ (-10 ∨ (16 ∨ (-7 ∨ (23 ∨ (-26 ∨ (-13 ∨ (-30 ∨ (19 ∨ (37 ∨ -12))))))))))) ∧ (9 ∨ (29 ∨ -20))) ∧ (-1 ∨ (-13 ∨ (12 ∨ 11)))) ∧ (24 ∨ (-14 ∨ (15 ∨ (-3 ∨ 30))))) ∧ (2 ∨ 8))\n",
      "23 = True in formula: ((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((-1 ∨ (-2 ∨ (-3 ∨ (4 ∨ (5 ∨ (6 ∨ (-7 ∨ (8 ∨ (-9 ∨ (-10 ∨ 11)))))))))) ∧ (-12 ∨ 13)) ∧ (-14 ∨ (2 ∨ -7))) ∧ (-15 ∨ (16 ∨ (-17 ∨ (-5 ∨ 18))))) ∧ (-4 ∨ (-19 ∨ 17))) ∧ (-9 ∨ (20 ∨ 21))) ∧ (-16 ∨ -22)) ∧ (-23 ∨ (-17 ∨ -24))) ∧ (4 ∨ (-25 ∨ -26))) ∧ (27 ∨ (28 ∨ (-5 ∨ (-11 ∨ -21))))) ∧ (-15 ∨ 3)) ∧ (-29 ∨ (4 ∨ (30 ∨ (17 ∨ -13))))) ∧ (-31 ∨ (32 ∨ -5))) ∧ (19 ∨ (-14 ∨ 29))) ∧ (3 ∨ (-1 ∨ -33))) ∧ (-29 ∨ (-21 ∨ 34))) ∧ (-27 ∨ (7 ∨ 1))) ∧ (-23 ∨ 26)) ∧ (8 ∨ (-7 ∨ (15 ∨ (-3 ∨ (-35 ∨ 1)))))) ∧ (-4 ∨ (12 ∨ 20))) ∧ (-24 ∨ (36 ∨ (-29 ∨ (32 ∨ (-34 ∨ -20)))))) ∧ (-37 ∨ (-30 ∨ (-21 ∨ (-32 ∨ (-24 ∨ -35)))))) ∧ (1 ∨ (-35 ∨ -3))) ∧ (8 ∨ (-1 ∨ (17 ∨ (-30 ∨ (-22 ∨ (-32 ∨ (27 ∨ 38)))))))) ∧ (15 ∨ (-14 ∨ -1))) ∧ (7 ∨ (-27 ∨ (-10 ∨ (-1 ∨ (2 ∨ -15)))))) ∧ (39 ∨ (34 ∨ (18 ∨ (24 ∨ (15 ∨ (-1 ∨ -17))))))) ∧ (38 ∨ (13 ∨ (31 ∨ (-14 ∨ (-21 ∨ -5)))))) ∧ (-22 ∨ (-25 ∨ (1 ∨ (-30 ∨ 38))))) ∧ (26 ∨ 12)) ∧ (23 ∨ (-34 ∨ (-26 ∨ 28)))) ∧ (3 ∨ (5 ∨ (-32 ∨ (14 ∨ (-2 ∨ (30 ∨ (-11 ∨ -21)))))))) ∧ (40 ∨ (7 ∨ (32 ∨ 11)))) ∧ (28 ∨ (1 ∨ (12 ∨ (15 ∨ (-19 ∨ (21 ∨ 7))))))) ∧ (-4 ∨ (33 ∨ (-19 ∨ 11)))) ∧ (32 ∨ (34 ∨ -37))) ∧ (36 ∨ (2 ∨ 6))) ∧ (25 ∨ (-17 ∨ (26 ∨ (-34 ∨ -6))))) ∧ (20 ∨ -26)) ∧ (-12 ∨ (-30 ∨ (-2 ∨ (-34 ∨ -24))))) ∧ (-7 ∨ (-28 ∨ -29))) ∧ (-30 ∨ (1 ∨ (38 ∨ (5 ∨ (-16 ∨ -37)))))) ∧ (-13 ∨ (-26 ∨ (-29 ∨ (4 ∨ 40))))) ∧ (-6 ∨ (-34 ∨ 35))) ∧ (-34 ∨ (-16 ∨ 38))) ∧ (-28 ∨ (-36 ∨ (-10 ∨ 16)))) ∧ (32 ∨ -25)) ∧ (34 ∨ (23 ∨ -38))) ∧ (-35 ∨ (-6 ∨ (11 ∨ (13 ∨ (-10 ∨ (4 ∨ -21))))))) ∧ (19 ∨ (-2 ∨ -16))) ∧ (22 ∨ (-18 ∨ (-12 ∨ -13)))) ∧ (-34 ∨ (13 ∨ (9 ∨ (-40 ∨ (-36 ∨ -2)))))) ∧ (11 ∨ (30 ∨ (14 ∨ 27)))) ∧ (28 ∨ (-19 ∨ 25))) ∧ (-34 ∨ (18 ∨ (17 ∨ (-33 ∨ (-27 ∨ (-11 ∨ (-28 ∨ (6 ∨ (16 ∨ (12 ∨ -2))))))))))) ∧ (-26 ∨ -2)) ∧ (-20 ∨ (-10 ∨ 25))) ∧ (8 ∨ (-27 ∨ (-35 ∨ 24)))) ∧ (20 ∨ (36 ∨ -24))) ∧ (-8 ∨ (-21 ∨ (20 ∨ (40 ∨ (3 ∨ (-34 ∨ (26 ∨ 7)))))))) ∧ (-36 ∨ (-22 ∨ (-26 ∨ (-8 ∨ 16))))) ∧ (28 ∨ (12 ∨ -37))) ∧ (17 ∨ (-24 ∨ (22 ∨ (-3 ∨ (15 ∨ -25)))))) ∧ (24 ∨ (-15 ∨ (-25 ∨ (-20 ∨ -29))))) ∧ (18 ∨ (-31 ∨ (-28 ∨ (22 ∨ -24))))) ∧ (-17 ∨ (-24 ∨ -2))) ∧ (-36 ∨ (22 ∨ 12))) ∧ (-28 ∨ -34)) ∧ (1 ∨ -16)) ∧ (4 ∨ (-17 ∨ -12))) ∧ (-31 ∨ (8 ∨ 36))) ∧ (33 ∨ (-39 ∨ 24))) ∧ (38 ∨ -3)) ∧ (-6 ∨ (25 ∨ -26))) ∧ (-12 ∨ (15 ∨ (38 ∨ (-28 ∨ (11 ∨ (22 ∨ (30 ∨ (5 ∨ (39 ∨ (8 ∨ (13 ∨ (16 ∨ (-21 ∨ (32 ∨ (9 ∨ (-19 ∨ 40))))))))))))))))) ∧ (14 ∨ (-17 ∨ (8 ∨ 1)))) ∧ (8 ∨ (-5 ∨ (35 ∨ (22 ∨ (12 ∨ (20 ∨ (-39 ∨ (7 ∨ (4 ∨ (33 ∨ (-18 ∨ (32 ∨ 21))))))))))))) ∧ (30 ∨ (-25 ∨ (23 ∨ (-38 ∨ -22))))) ∧ (8 ∨ (11 ∨ -2))) ∧ (-27 ∨ (-14 ∨ (38 ∨ (31 ∨ (-40 ∨ 33)))))) ∧ (25 ∨ (18 ∨ (10 ∨ (35 ∨ 29))))) ∧ (-23 ∨ (10 ∨ (8 ∨ (35 ∨ (-6 ∨ 5)))))) ∧ (34 ∨ (-26 ∨ (37 ∨ -29)))) ∧ (31 ∨ (-7 ∨ -1))) ∧ (-10 ∨ (35 ∨ (38 ∨ -37)))) ∧ (-14 ∨ (23 ∨ (-39 ∨ (-17 ∨ (15 ∨ (-16 ∨ (-7 ∨ 22)))))))) ∧ (34 ∨ (17 ∨ 19))) ∧ (24 ∨ (-16 ∨ (11 ∨ (23 ∨ 40))))) ∧ (-10 ∨ (-35 ∨ (15 ∨ 38)))) ∧ (25 ∨ -27)) ∧ (-26 ∨ (40 ∨ -25))) ∧ (-37 ∨ (-39 ∨ 24))) ∧ (5 ∨ (39 ∨ (-3 ∨ -35)))) ∧ (18 ∨ (29 ∨ -9))) ∧ (-21 ∨ (-33 ∨ -7))) ∧ (-5 ∨ (26 ∨ 16))) ∧ (12 ∨ (-8 ∨ (24 ∨ (10 ∨ -39))))) ∧ (18 ∨ (3 ∨ (4 ∨ (15 ∨ (-10 ∨ 29)))))) ∧ (31 ∨ (23 ∨ (-39 ∨ 32)))) ∧ (19 ∨ 28)) ∧ (-12 ∨ (3 ∨ (37 ∨ 35)))) ∧ (-2 ∨ (-12 ∨ (-6 ∨ (-15 ∨ 4))))) ∧ (28 ∨ (-5 ∨ (36 ∨ 3)))) ∧ (-3 ∨ (26 ∨ (40 ∨ 24)))) ∧ (-6 ∨ (-23 ∨ (-29 ∨ (-30 ∨ -18))))) ∧ (-35 ∨ -25)) ∧ (-40 ∨ 26)) ∧ (-7 ∨ (-15 ∨ 22))) ∧ (16 ∨ (-21 ∨ (20 ∨ (34 ∨ (-37 ∨ (10 ∨ (-8 ∨ (17 ∨ (-9 ∨ (22 ∨ -38))))))))))) ∧ (39 ∨ (-10 ∨ (-26 ∨ -32)))) ∧ (24 ∨ (-40 ∨ -3))) ∧ (-23 ∨ (-39 ∨ (-31 ∨ -15)))) ∧ (9 ∨ -5)) ∧ (-8 ∨ (40 ∨ (-14 ∨ (-34 ∨ (-17 ∨ (-16 ∨ (13 ∨ (-29 ∨ (35 ∨ -1)))))))))) ∧ (-19 ∨ (-33 ∨ (-27 ∨ (21 ∨ (10 ∨ (-9 ∨ 31))))))) ∧ (30 ∨ (22 ∨ -7))) ∧ (39 ∨ (4 ∨ -1))) ∧ (32 ∨ (-7 ∨ -24))) ∧ (39 ∨ (7 ∨ 32))) ∧ (-4 ∨ (-32 ∨ (18 ∨ (-29 ∨ -28))))) ∧ (-11 ∨ (8 ∨ (-31 ∨ (-6 ∨ -15))))) ∧ (-35 ∨ (-10 ∨ 16))) ∧ (-37 ∨ (-3 ∨ (-9 ∨ -33)))) ∧ (-29 ∨ (34 ∨ -35))) ∧ (23 ∨ (29 ∨ (-27 ∨ 19)))) ∧ (-31 ∨ (37 ∨ (-2 ∨ (1 ∨ 4))))) ∧ (27 ∨ (38 ∨ (-18 ∨ (29 ∨ -26))))) ∧ (-2 ∨ (24 ∨ (19 ∨ 1)))) ∧ (35 ∨ (13 ∨ 31))) ∧ (28 ∨ 21)) ∧ (11 ∨ (13 ∨ (-10 ∨ 25)))) ∧ (-37 ∨ (-19 ∨ (38 ∨ (-16 ∨ (-31 ∨ 5)))))) ∧ (23 ∨ (9 ∨ (-35 ∨ (-19 ∨ -21))))) ∧ (-13 ∨ (16 ∨ -9))) ∧ (-40 ∨ (-32 ∨ (-22 ∨ (13 ∨ -31))))) ∧ (-22 ∨ (-10 ∨ 34))) ∧ (35 ∨ (-29 ∨ (19 ∨ 15)))) ∧ (3 ∨ (14 ∨ -26))) ∧ (-14 ∨ (-3 ∨ -30))) ∧ (-21 ∨ (10 ∨ (-7 ∨ (-13 ∨ 4))))) ∧ (20 ∨ (17 ∨ 7))) ∧ (5 ∨ (38 ∨ (17 ∨ (-16 ∨ 2))))) ∧ (39 ∨ (-33 ∨ (-14 ∨ (-8 ∨ (9 ∨ (35 ∨ 24))))))) ∧ (-22 ∨ (-8 ∨ -11))) ∧ (-38 ∨ -26)) ∧ (-19 ∨ (37 ∨ 18))) ∧ (25 ∨ (6 ∨ -34))) ∧ (-3 ∨ (30 ∨ 20))) ∧ (12 ∨ (7 ∨ (17 ∨ (20 ∨ 33))))) ∧ (-14 ∨ (-40 ∨ (-10 ∨ (-12 ∨ (-19 ∨ -23)))))) ∧ (20 ∨ (-4 ∨ 1))) ∧ (-5 ∨ (-26 ∨ -8))) ∧ (-8 ∨ (26 ∨ (16 ∨ (-10 ∨ (-12 ∨ (-18 ∨ (-39 ∨ (29 ∨ (25 ∨ (11 ∨ -30))))))))))) ∧ (-19 ∨ (-33 ∨ (-21 ∨ (18 ∨ 16))))) ∧ (26 ∨ (-21 ∨ -6))) ∧ (18 ∨ (-32 ∨ -38))) ∧ (10 ∨ (-16 ∨ (-27 ∨ 40)))) ∧ (14 ∨ (30 ∨ (15 ∨ (-20 ∨ (-40 ∨ 24)))))) ∧ (-39 ∨ (-12 ∨ (13 ∨ (-21 ∨ -37))))) ∧ (-18 ∨ 3)) ∧ (32 ∨ -33)) ∧ (-26 ∨ (-13 ∨ (10 ∨ (-19 ∨ -2))))) ∧ (29 ∨ (-39 ∨ -37))) ∧ (-28 ∨ -21)) ∧ (-5 ∨ (-35 ∨ 33))) ∧ (6 ∨ (24 ∨ -4))) ∧ (-17 ∨ (-11 ∨ (-5 ∨ (-28 ∨ -7))))) ∧ (-22 ∨ (-2 ∨ (24 ∨ (-16 ∨ -40))))) ∧ (31 ∨ (-11 ∨ -7))) ∧ (-6 ∨ (-8 ∨ (22 ∨ (32 ∨ (25 ∨ (-10 ∨ -24))))))) ∧ (25 ∨ (38 ∨ (-10 ∨ (-8 ∨ 1))))) ∧ (15 ∨ 28)) ∧ (-22 ∨ -40)) ∧ (36 ∨ (20 ∨ (11 ∨ -1)))) ∧ (27 ∨ -3)) ∧ (12 ∨ (4 ∨ 3))) ∧ (6 ∨ (-1 ∨ (24 ∨ (-3 ∨ (-5 ∨ (38 ∨ (-26 ∨ (-36 ∨ -20))))))))) ∧ (-15 ∨ (16 ∨ (-23 ∨ (4 ∨ -29))))) ∧ (-9 ∨ (-20 ∨ -23))) ∧ (-20 ∨ (-6 ∨ 24))) ∧ (-32 ∨ (33 ∨ 22))) ∧ (-29 ∨ (-5 ∨ (32 ∨ -2)))) ∧ (-11 ∨ (-19 ∨ 39))) ∧ (-33 ∨ (-29 ∨ 12))) ∧ (32 ∨ (25 ∨ (5 ∨ (-12 ∨ (37 ∨ (-29 ∨ (27 ∨ (-8 ∨ (20 ∨ (19 ∨ (-9 ∨ (34 ∨ (-16 ∨ 28)))))))))))))) ∧ (-35 ∨ (11 ∨ (-29 ∨ -8)))) ∧ (-29 ∨ (21 ∨ (-33 ∨ (-31 ∨ (-7 ∨ (9 ∨ 27))))))) ∧ (39 ∨ (-6 ∨ (4 ∨ 25)))) ∧ (-21 ∨ (25 ∨ (-3 ∨ 38)))) ∧ (21 ∨ 24)) ∧ (-36 ∨ (-6 ∨ -5))) ∧ (38 ∨ (-12 ∨ (7 ∨ -39)))) ∧ (20 ∨ (24 ∨ (10 ∨ 9)))) ∧ (22 ∨ -21)) ∧ (19 ∨ 11)) ∧ (-13 ∨ (-17 ∨ (-7 ∨ (16 ∨ 40))))) ∧ (-38 ∨ (-7 ∨ (21 ∨ (22 ∨ (17 ∨ (-37 ∨ 36))))))) ∧ (-9 ∨ 30)) ∧ (5 ∨ (-6 ∨ -32))) ∧ (-10 ∨ (-27 ∨ (31 ∨ (-2 ∨ (32 ∨ -13)))))) ∧ (40 ∨ (6 ∨ (19 ∨ (-37 ∨ -39))))) ∧ (-27 ∨ 4)) ∧ (40 ∨ (-26 ∨ (3 ∨ -37)))) ∧ (15 ∨ (-27 ∨ 3))) ∧ (20 ∨ (-33 ∨ 23))) ∧ (-15 ∨ (-33 ∨ -29))) ∧ (-4 ∨ 37)) ∧ (-26 ∨ 14)) ∧ (-31 ∨ (18 ∨ (34 ∨ -30)))) ∧ (35 ∨ -7)) ∧ (-6 ∨ (-1 ∨ 22))) ∧ (-32 ∨ -10))\n"
     ]
    }
   ],
   "source": [
    "for formula, (var, assignment) in decisions[:3]:\n",
    "    print(\"{} = {} in formula: {}\".format(var, assignment, expression.pprint(formula)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training/test sets.\n",
    "num_training = int(len(decisions) * TRAIN_SPLIT)\n",
    "decisions_training, decisions_test = decisions[:num_training], decisions[num_training:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how the approximate optimal heuristic is distributed. We're expecting a roughly uniform distribution over variable names, as variables are initially named randomly and our renaming is a bijection, preserving its randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "picked_vars, picked_assignments = zip(*((int(var), int(assignment)) for _, (var, assignment) in decisions))\n",
    "picked_vars, picked_assignments = np.array(picked_vars), np.array(picked_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(picked_vars, vocab_size)\n",
    "plt.title('Best variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAUBklEQVR4nO3df7RlZX3f8fcHRsT6C3AGQmeAi8sxlbiK0imQZVqNWBhIyrBWwYzVMrBYndaQNk1IE9Q/MBiyNFkNDav+CAkTR1cNTGwMU6UhU4RKswIyiBCBUEYgcAMyIzOgFqWA3/5xnjFHvD/OZe49l8vzfq1119n7u5999vPMvfO5+z57n3NSVUiS+rDfYndAkjQ+hr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfXUnyZ1J3rbY/ZAWQ7xPX0tFkhuAY4Efq6qnFrk7Y5Xkg8Drquo9i90XLW2e6WtJSDIB/BOggNMXtTPSEmboa6k4G7gJ+CSwYW8xyWlJ7kry7SR/m+RXWn15ks8neTzJ7iQ3JtmvbXsgyTva8suSbE6yJ8ndSX41yeTQ8z+Q5FeS3JHkiSRXJTmwbXtbksm2z84kjyQ5o/Xp/7Tjvn/oufZLcmGSryd5LMmWJIe0bRNJKsmGJA8m+WaSD7Rta4H3Az+X5DtJbm/1c5Lc18Z+f5J3L+Q3QC8Oyxa7A9KIzgZ+B7gZuCnJYVX1KHAF8M6qujHJwcDRrf0FwCSwoq2fyOCvhOe6CJgAXgu8HLhmijbvBNYC3wP+AjgH+ETb9mPAgcDKVv99YBvwj4AjgVuTXFlV9wH/HjgDeCuwC7gM+CjwrqFj/RTw48DrgS8n+ZOq+rMkv8nQ9E6Sl7f9/3FV3ZPkcOCQGf79JMAzfS0BSX4KOArYUlW3Al8H/mXb/DRwTJJXVdWeqvrKUP1w4KiqerqqbqypL2C9E/jNtu8kgyB9rsuq6uGq2g38d+BNQ9ueBi6pqqeBK4HlwO9W1ber6k7gTuAftrb/BvhAVU22axIfBM5MMnzy9etV9d2quh24ncE1jOl8H3hjkpdV1SPteNKMDH0tBRuAP6+qb7b1z/B3Uzz/AjgN+Jsk/yvJT7b6bwM7gD9vUyAXTvPcfx94aGj9oSnafGNo+UngFUPrj1XVs235u+3x0aHt3x1qfxTwuTbl9DhwN/AscNiIx/qBqvq/wM8B/xZ4JMkXkvyDqdpKwwx9vaAleRmDs/G3JvlGkm8AvwQcm+TYqrqlqtYBhwJ/CmwBaGfaF1TVa4F/DvxykpOmOMQjwKqh9SMWcDgPAadW1UFDXwdW1d+OsO+P/JVSVddW1T9j8BfNXzOYWpJmZOjrhe4MBmfDxzCYVnkT8AbgRuCcJO9O8uo2vfKt1pYkP5vkdUkyVH92iuffArwvycFJVgK/sIBj+QRwSZKjWh9XJFk34r6PAhNDF6MPS3J6m9t/CvgOU49P+iGGvl7oNgB/WFUPVtU39n4B/6VtOxd4IMm3GEx17L2PfTXwPxmE4V8CH6uqG6Z4/osZXPC9v7X/LIMQXQi/C2xlMOX0bQZ3I50w4r5/3B4fS/IVBv93LwAeBnYzuDj88/PbXb0Y+eIsaUiS9wLrq+qti90XaSF4pq+uJTk8yVvaPfQ/zuDs+XOL3S9poXifvnp3APB7DO7vf5zBbZcfW9QeSQvI6R1J6ojTO5LUkRf09M7y5ctrYmJisbshSUvKrbfe+s2qWjHVthd06E9MTLB9+/bF7oYkLSlJ/ma6bU7vSFJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjoyUugneSDJXyX5apLtrXZIkm1J7m2PB7d6klyWZEeSO5IcN/Q8G1r7e5NsmO54kqSFMZdX5P700GeUAlwIXFdVH26fP3oh8GvAqQw+wGI1gw+I+DhwQpJDgIuANQw++u3WJFuras88jEMau4kLv7DYXdCL2AMf/pkFed59md5ZB2xuy5sZfKzd3vqnauAm4KAkhwOnANuqancL+m3A2n04viRpjkYN/WLwEW+3JtnYaodV1SMA7fHQVl/J4AOg95pstenqkqQxGXV65y1V9XCSQ4FtSf56hraZolYz1H9458EvlY0ARx555IjdkySNYqQz/ap6uD3uZPBRcscDj7ZpG9rjztZ8EjhiaPdVDD68ebr6c491eVWtqao1K1ZM+c6gkqTnadbQT/LyJK/cuwycDHwN2ArsvQNnA3B1W94KnN3u4jkReKJN/1wLnJzk4Hanz8mtJkkak1Gmdw4DPpdkb/vPVNWfJbkF2JLkPOBB4KzW/hrgNGAH8CRwLkBV7U7yIeCW1u7iqto9byORJM1q1tCvqvuAY6eoPwacNEW9gPOnea5NwKa5d1OSNB98Ra4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZJSPS1yyJi78wmJ3QZJeUDzTl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdGTn0k+yf5LYkn2/rRye5Ocm9Sa5KckCrv7St72jbJ4ae432tfk+SU+Z7MJKkmc3lTP8XgbuH1j8CXFpVq4E9wHmtfh6wp6peB1za2pHkGGA98BPAWuBjSfbft+5LkuZipNBPsgr4GeAP2nqAtwOfbU02A2e05XVtnbb9pNZ+HXBlVT1VVfcDO4Dj52MQkqTRjHqm/5+BXwW+39ZfAzxeVc+09UlgZVteCTwE0LY/0dr/oD7FPj+QZGOS7Um279q1aw5DkSTNZtbQT/KzwM6qunW4PEXTmmXbTPv8XaHq8qpaU1VrVqxYMVv3JElzMMpn5L4FOD3JacCBwKsYnPkflGRZO5tfBTzc2k8CRwCTSZYBrwZ2D9X3Gt5HkjQGs57pV9X7qmpVVU0wuBD7xap6N3A9cGZrtgG4ui1vbeu07V+sqmr19e3unqOB1cCX520kkqRZjXKmP51fA65M8hvAbcAVrX4F8OkkOxic4a8HqKo7k2wB7gKeAc6vqmf34fiSpDmaU+hX1Q3ADW35Pqa4+6aqvgecNc3+lwCXzLWTkqT54StyJakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR2ZNfSTHJjky0luT3Jnkl9v9aOT3Jzk3iRXJTmg1V/a1ne07RNDz/W+Vr8nySkLNShJ0tRGOdN/Cnh7VR0LvAlYm+RE4CPApVW1GtgDnNfanwfsqarXAZe2diQ5BlgP/ASwFvhYkv3nczCSpJnNGvo18J22+pL2VcDbgc+2+mbgjLa8rq3Ttp+UJK1+ZVU9VVX3AzuA4+dlFJKkkYw0p59k/yRfBXYC24CvA49X1TOtySSwsi2vBB4CaNufAF4zXJ9in+FjbUyyPcn2Xbt2zX1EkqRpjRT6VfVsVb0JWMXg7PwNUzVrj5lm23T15x7r8qpaU1VrVqxYMUr3JEkjmtPdO1X1OHADcCJwUJJlbdMq4OG2PAkcAdC2vxrYPVyfYh9J0hiMcvfOiiQHteWXAe8A7gauB85szTYAV7flrW2dtv2LVVWtvr7d3XM0sBr48nwNRJI0u2WzN+FwYHO702Y/YEtVfT7JXcCVSX4DuA24orW/Avh0kh0MzvDXA1TVnUm2AHcBzwDnV9Wz8zscSdJMZg39qroDePMU9fuY4u6bqvoecNY0z3UJcMncuylJmg++IleSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkVlDP8kRSa5PcneSO5P8YqsfkmRbknvb48GtniSXJdmR5I4kxw0914bW/t4kGxZuWJKkqYxypv8McEFVvQE4ETg/yTHAhcB1VbUauK6tA5wKrG5fG4GPw+CXBHARcAJwPHDR3l8UkqTxmDX0q+qRqvpKW/42cDewElgHbG7NNgNntOV1wKdq4CbgoCSHA6cA26pqd1XtAbYBa+d1NJKkGc1pTj/JBPBm4GbgsKp6BAa/GIBDW7OVwENDu0222nT15x5jY5LtSbbv2rVrLt2TJM1i5NBP8grgvwH/oaq+NVPTKWo1Q/2HC1WXV9WaqlqzYsWKUbsnSRrBSKGf5CUMAv+/VtWftPKjbdqG9riz1SeBI4Z2XwU8PENdkjQmo9y9E+AK4O6q+p2hTVuBvXfgbACuHqqf3e7iORF4ok3/XAucnOTgdgH35FaTJI3JshHavAX4V8BfJflqq70f+DCwJcl5wIPAWW3bNcBpwA7gSeBcgKraneRDwC2t3cVVtXteRiFJGsmsoV9V/5up5+MBTpqifQHnT/Ncm4BNc+mgJGn++IpcSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkdmDf0km5LsTPK1odohSbYlubc9HtzqSXJZkh1J7khy3NA+G1r7e5NsWJjhSJJmMsqZ/ieBtc+pXQhcV1WrgevaOsCpwOr2tRH4OAx+SQAXAScAxwMX7f1FIUkan1lDv6q+BOx+TnkdsLktbwbOGKp/qgZuAg5KcjhwCrCtqnZX1R5gGz/6i0SStMCe75z+YVX1CEB7PLTVVwIPDbWbbLXp6j8iycYk25Ns37Vr1/PsniRpKvN9ITdT1GqG+o8Wqy6vqjVVtWbFihXz2jlJ6t3zDf1H27QN7XFnq08CRwy1WwU8PENdkjRGzzf0twJ778DZAFw9VD+73cVzIvBEm/65Fjg5ycHtAu7JrSZJGqNlszVI8kfA24DlSSYZ3IXzYWBLkvOAB4GzWvNrgNOAHcCTwLkAVbU7yYeAW1q7i6vquReHJUkLbNbQr6p3TbPppCnaFnD+NM+zCdg0p95JkuaVr8iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdWTsoZ9kbZJ7kuxIcuG4jy9JPRtr6CfZH/gocCpwDPCuJMeMsw+S1LNxn+kfD+yoqvuq6v8BVwLrxtwHSerWsjEfbyXw0ND6JHDCcIMkG4GNbfU7Se7Zh+MtB765D/svNb2NFxxzL7obcz6yT2M+aroN4w79TFGrH1qpuhy4fF4OlmyvqjXz8VxLQW/jBcfcC8c8f8Y9vTMJHDG0vgp4eMx9kKRujTv0bwFWJzk6yQHAemDrmPsgSd0a6/ROVT2T5BeAa4H9gU1VdecCHnJepomWkN7GC465F455nqSqZm8lSXpR8BW5ktQRQ1+SOrLkQ3+2t3VI8tIkV7XtNyeZGH8v59cIY/7lJHcluSPJdUmmvWd3qRj17TuSnJmkkiz52/tGGXOSd7bv9Z1JPjPuPs63EX62j0xyfZLb2s/3aYvRz/mSZFOSnUm+Ns32JLms/XvckeS4fT5oVS3ZLwYXg78OvBY4ALgdOOY5bX4e+ERbXg9ctdj9HsOYfxr4e235vT2MubV7JfAl4CZgzWL3ewzf59XAbcDBbf3Qxe73GMZ8OfDetnwM8MBi93sfx/xPgeOAr02z/TTgfzB4jdOJwM37esylfqY/yts6rAM2t+XPAiclmepFYkvFrGOuquur6sm2ehOD10MsZaO+fceHgN8CvjfOzi2QUcb8r4GPVtUegKraOeY+zrdRxlzAq9ryq1nir/Opqi8Bu2dosg74VA3cBByU5PB9OeZSD/2p3tZh5XRtquoZ4AngNWPp3cIYZczDzmNwprCUzTrmJG8Gjqiqz4+zYwtolO/z64HXJ/mLJDclWTu23i2MUcb8QeA9SSaBa4B/N56uLZq5/n+f1bjfhmG+zfq2DiO2WUpGHk+S9wBrgLcuaI8W3oxjTrIfcClwzrg6NAajfJ+XMZjieRuDv+ZuTPLGqnp8gfu2UEYZ87uAT1bVf0ryk8Cn25i/v/DdWxTznl9L/Ux/lLd1+EGbJMsY/Ek4059TL3QjvZVFkncAHwBOr6qnxtS3hTLbmF8JvBG4IckDDOY+ty7xi7mj/mxfXVVPV9X9wD0MfgksVaOM+TxgC0BV/SVwIIM3Y3uxmve3rlnqoT/K2zpsBTa05TOBL1a7QrJEzTrmNtXxewwCf6nP88IsY66qJ6pqeVVNVNUEg+sYp1fV9sXp7rwY5Wf7TxlctCfJcgbTPfeNtZfza5QxPwicBJDkDQxCf9dYezleW4Gz2108JwJPVNUj+/KES3p6p6Z5W4ckFwPbq2orcAWDPwF3MDjDX794Pd53I475t4FXAH/crlk/WFWnL1qn99GIY35RGXHM1wInJ7kLeBb4j1X12OL1et+MOOYLgN9P8ksMpjnOWconcUn+iMH03PJ2neIi4CUAVfUJBtctTgN2AE8C5+7zMZfwv5ckaY6W+vSOJGkODH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkf8PdkDXfABnM5wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(picked_assignments, 2)\n",
    "plt.title('Assignments')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the LSTM model, we need to convert our dataset of formulas in AST form into a sequence of tokens. We're going to do some preprocessing:\n",
    "\n",
    "- We're going to convert variables into one-hot vectors; and connectives into special one-hot tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_length = vocab_size + 2 # for connectives AND and OR\n",
    "\n",
    "def one_hot(length: int, index: int):\n",
    "    element = -1 if index < 0 else 1\n",
    "    index = abs(index)\n",
    "    \n",
    "    v = [0] * length\n",
    "    v[index] = element\n",
    "    return v\n",
    "\n",
    "SPECIAL_TOKENS = {\n",
    "    expression.Type.AND: one_hot(token_length, vocab_size),\n",
    "    expression.Type.OR: one_hot(token_length, vocab_size + 1)\n",
    "}\n",
    "\n",
    "def tokenize_formula(formula):\n",
    "    return torch.FloatTensor(_tokenize_formula(formula))\n",
    "\n",
    "def _tokenize_formula(formula):\n",
    "    if not formula:\n",
    "        return []\n",
    "    \n",
    "    assert isinstance(formula, expression.Expression)\n",
    "    \n",
    "    typ, l_val, r_val = formula\n",
    "\n",
    "    # We're at a variable, embed it.\n",
    "    if typ == expression.Type.VAR:\n",
    "        # Variables are 1-indexed\n",
    "        zero_idx = int(l_val) - 1\n",
    "        return [one_hot(token_length, zero_idx)]\n",
    "    # We're at a NOT'd variable, reach one level below and embed it.\n",
    "    if typ == expression.Type.NOT:\n",
    "        assert l_val.typ == expression.Type.VAR, \"Expecting negations to be propagated to literal level\"\n",
    "        zero_idx = int(l_val.l_val) - 1\n",
    "        return [one_hot(token_length, -1 * zero_idx)]\n",
    "\n",
    "    # Else join tokenizations of branches into one sequence\n",
    "    return _tokenize_formula(l_val) + [SPECIAL_TOKENS[typ]] + _tokenize_formula(r_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that we have formula sequences, we must have labels for these formulas. Our formula labels are in $\\mathbb{Z} \\times \\{0, 1\\}$, with the first element bounded by `vocab_size`. We're simply going to index into the Cartesian product of these sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "label_length = vocab_size * 2\n",
    "\n",
    "def tokenize_policy(policy: Tuple[int, bool]) -> int:\n",
    "    \"\"\"Torch's log-softmax expects ordinal integers as classes, so we do that.\"\"\"\n",
    "    idx, branch = policy\n",
    "    zero_idx = idx - 1\n",
    "    return zero_idx * 2 + int(branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(decisions):\n",
    "    X, y = zip(*((tokenize_formula(formula), tokenize_policy(policy)) for formula, policy in decisions))\n",
    "    return X, y\n",
    "\n",
    "# List of 2D tensors, List of 1D tensors\n",
    "X_train, y_train = tokenize_dataset(decisions_training)\n",
    "X_test, y_test = tokenize_dataset(decisions_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "\n",
    "Now let's try a traditional LSTM approach in predicting this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LSTMDataset(data.Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        \"\"\"Expects a list of 2D tensors (sequences) and a list of vectors (labels)\"\"\"\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.sequences[index], self.labels[index]\n",
    "    \n",
    "def lstm_collator(batch):\n",
    "    \"\"\"Expects `batch` to be a list of (X, y) pairs.\"\"\"\n",
    "    X, y = zip(*batch)\n",
    "    seq_lens = torch.tensor([len(seq) for seq in X])\n",
    "    padded_sequences = nn.utils.rnn.pad_sequence(X, batch_first=True)\n",
    "    packed_batch = nn.utils.rnn.pack_padded_sequence(\n",
    "        padded_sequences,\n",
    "        seq_lens,\n",
    "        batch_first=True,\n",
    "        enforce_sorted=False\n",
    "    )\n",
    "    \n",
    "    return packed_batch, torch.LongTensor(y)\n",
    "\n",
    "dataset_train = LSTMDataset(X_train, y_train)\n",
    "dataset_test = LSTMDataset(X_test, y_test)\n",
    "\n",
    "loader_opts = {\n",
    "    'collate_fn': lstm_collator,\n",
    "    'batch_size': 32,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 4\n",
    "}\n",
    "\n",
    "loader_train = data.DataLoader(dataset=dataset_train, **loader_opts)\n",
    "loader_test = data.DataLoader(dataset=dataset_test, **loader_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, linear_dims: List[int], num_lstm_layers: int):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, num_lstm_layers, batch_first=True)\n",
    "        \n",
    "        input_dims = [self.hidden_dim] + linear_dims[:-1]\n",
    "        self.linears = [nn.Linear(input, output) for input, output in zip(input_dims, linear_dims)]\n",
    "        \n",
    "    def forward(self, packed_input):\n",
    "        \"\"\"Expects a packed sequence.\"\"\"\n",
    "        _, (hidden, _) = self.lstm(packed_input)\n",
    "        x = hidden[-1]\n",
    "        \n",
    "        for linear in self.linears:\n",
    "            x = linear(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300 Step 1/119 Train loss: 0.08785226821899414 Train acc: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1b1b3ac4f4ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/sat-ml/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/envs/sat-ml/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LSTM(\n",
    "    input_dim=token_length,\n",
    "    hidden_dim=5,\n",
    "    linear_dims=[8, label_length],\n",
    "    num_lstm_layers=1\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters()) # Use the default LR schedule\n",
    "\n",
    "EPOCHS = 300\n",
    "print_every = 50\n",
    "running_loss, running_accuracy = 0, 0\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "    for step, (X, y) in enumerate(loader_train):\n",
    "        model.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            class_predictions = y_pred.max(1)[1]            \n",
    "            num_accurate = class_predictions.eq(y).sum()\n",
    "            \n",
    "            running_loss += (loss.item() / print_every)\n",
    "            running_accuracy += (float(num_accurate) / (y.shape[0] * print_every))\n",
    "        \n",
    "            if step % print_every == 0:\n",
    "                print(f\"Epoch {t + 1}/{EPOCHS} \"\n",
    "                      f\"Step {step + 1}/{len(loader_train)} \"\n",
    "                      f\"Train loss: {running_loss} \"\n",
    "                      f\"Train acc: {running_accuracy}\")\n",
    "                running_loss, running_accuracy = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
